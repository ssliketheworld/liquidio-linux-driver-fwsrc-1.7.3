# Every NIC provides some set of tunings. This is a start for liquidio with a standard 
# set of sysctl trying to increase socket and TCP/IP buffer limits. Bound to change
# with further testing. Raghu
#
# some of the defaults may be different for your kernel
# call this file with sysctl -p <this file>
# these are just suggested values that worked well to increase throughput in
# several network benchmark tests, your mileage may vary

### IPV4 specific settings
# turn TCP timestamp support off, default 1, reduces CPU use
net.ipv4.tcp_timestamps = 0 
# turn SACK support off, default on
# on systems with a VERY fast bus -> memory interface this is the big gainer
net.ipv4.tcp_sack = 0 
# set min/default/max TCP read buffer, default 4096 87380 174760
net.ipv4.tcp_rmem = 10000000 10000000 10000000 
# set min/pressure/max TCP write buffer, default 4096 16384 131072
net.ipv4.tcp_wmem = 10000000 10000000 10000000 
# set min/pressure/max TCP buffer space, default 31744 32256 32768
net.ipv4.tcp_mem = 10000000 10000000 10000000 

### CORE settings (mostly for socket and UDP effect)
# set maximum receive socket buffer size, default 131071 
net.core.rmem_max = 524287 
# set maximum send socket buffer size, default 131071
net.core.wmem_max = 524287 
# set default receive socket buffer size, default 65535
net.core.rmem_default = 524287 
# set default send socket buffer size, default 65535
net.core.wmem_default = 524287 
# set maximum amount of option memory buffers, default 10240
net.core.optmem_max = 524287 
# set number of unprocessed input packets before kernel starts dropping them; default 300
net.core.netdev_max_backlog = 300000 
